{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取 Block 9 Token 500 的 Attention Map 和 Value\n",
    "\n",
    "本 notebook 用於提取 3 個 frame 的 block 9 中 token 500 的：\n",
    "- Attention Map（注意力權重分佈）\n",
    "- Attention Values（如需要也可以提取 V 矩陣）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 載入必要的套件和模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize_attention import (\n",
    "    AttentionExtractor,\n",
    "    extract_both_attentions,\n",
    "    visualize_attention_on_image,\n",
    "    get_attention_values\n",
    ")\n",
    "from vggt.models.vggt import VGGT\n",
    "from vggt.utils.load_fn import load_and_preprocess_images\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 設定裝置\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"使用裝置: {device}\")\n",
    "\n",
    "# 載入模型\n",
    "print(\"載入 VGGT 模型...\")\n",
    "model = VGGT.from_pretrained(\"facebook/VGGT-1B\").to(device)\n",
    "model.eval()\n",
    "print(\"模型載入完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 載入 3 張圖片\n",
    "\n",
    "請修改 `image_paths` 為你想要使用的 3 張圖片路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改這裡的圖片路徑\n",
    "image_paths = [\n",
    "    \"examples/llff_flower/images/000.png\",\n",
    "    \"examples/llff_flower/images/005.png\",\n",
    "    \"examples/llff_flower/images/010.png\"\n",
    "]\n",
    "\n",
    "# 載入並預處理圖片\n",
    "print(f\"載入 {len(image_paths)} 張圖片...\")\n",
    "images = load_and_preprocess_images(image_paths).to(device)\n",
    "print(f\"圖片 shape: {images.shape}\")\n",
    "print(\"圖片載入完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 提取 Block 9 的 Attention\n",
    "\n",
    "提取 block 9 的 frame attention 和 global attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取 block 9 的 attention\n",
    "block_idx = 9\n",
    "token_idx = 500\n",
    "head_idx = 0  # 可以修改為其他 head\n",
    "\n",
    "print(f\"提取 Block {block_idx} 的 attention...\")\n",
    "result = extract_both_attentions(model, images, block_idx=block_idx)\n",
    "\n",
    "print(\"\\n提取結果：\")\n",
    "print(f\"  Frame Attention shape: {result['frame_attention']['attn_weights'].shape}\")\n",
    "print(f\"  Global Attention shape: {result['global_attention']['attn_weights'].shape}\")\n",
    "print(f\"  Patch start index: {result['patch_start_idx']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 提取 Token 500 的 Attention Map（數值）\n",
    "\n",
    "### 4.1 Global Attention - 3 個 Frame 的 Attention Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取 global attention 的純數值\n",
    "global_values = get_attention_values(\n",
    "    attn_weights=result['global_attention']['attn_weights'],\n",
    "    images=images,\n",
    "    token_idx=token_idx,\n",
    "    head_idx=head_idx,\n",
    "    patch_start_idx=result['patch_start_idx'],\n",
    "    attention_type='global'\n",
    ")\n",
    "\n",
    "print(\"Global Attention Values:\")\n",
    "print(f\"  Attention maps shape: {global_values['attention_maps'].shape}\")  # [3, grid_h, grid_w]\n",
    "print(f\"  Attention maps resized shape: {global_values['attention_maps_resized'].shape}\")  # [3, H, W]\n",
    "print(f\"  Images shape: {global_values['images'].shape}\")  # [3, H, W, 3]\n",
    "print(f\"\\nMetadata:\")\n",
    "for key, value in global_values['metadata'].items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Frame Attention - 第一個 Frame 的 Attention Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取 frame attention 的純數值\n",
    "frame_values = get_attention_values(\n",
    "    attn_weights=result['frame_attention']['attn_weights'],\n",
    "    images=images,\n",
    "    token_idx=token_idx,\n",
    "    head_idx=head_idx,\n",
    "    patch_start_idx=result['patch_start_idx'],\n",
    "    attention_type='frame'\n",
    ")\n",
    "\n",
    "print(\"Frame Attention Values:\")\n",
    "print(f\"  Attention maps shape: {frame_values['attention_maps'].shape}\")  # [grid_h, grid_w]\n",
    "print(f\"  Attention maps resized shape: {frame_values['attention_maps_resized'].shape}\")  # [H, W]\n",
    "print(f\"\\nMetadata:\")\n",
    "for key, value in frame_values['metadata'].items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 視覺化 Attention Map\n",
    "\n",
    "### 5.1 視覺化 Global Attention（3 個 Frame）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化 global attention\n",
    "fig_global = visualize_attention_on_image(\n",
    "    attn_weights=result['global_attention']['attn_weights'],\n",
    "    images=images,\n",
    "    token_idx=token_idx,\n",
    "    head_idx=head_idx,\n",
    "    patch_start_idx=result['patch_start_idx'],\n",
    "    attention_type='global',\n",
    "    layer_name=f'Block {block_idx}'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 視覺化 Frame Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化 frame attention\n",
    "fig_frame = visualize_attention_on_image(\n",
    "    attn_weights=result['frame_attention']['attn_weights'],\n",
    "    images=images,\n",
    "    token_idx=token_idx,\n",
    "    head_idx=head_idx,\n",
    "    patch_start_idx=result['patch_start_idx'],\n",
    "    attention_type='frame',\n",
    "    layer_name=f'Block {block_idx}'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 查看具體的 Attention 數值\n",
    "\n",
    "### 6.1 查看每個 Frame 的 Attention 統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看 3 個 frame 的 attention 統計資訊\n",
    "print(\"Global Attention 統計（Token 500 對 3 個 Frame 的注意力）:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for frame_idx in range(3):\n",
    "    frame_attn = global_values['attention_maps'][frame_idx]\n",
    "    print(f\"\\nFrame {frame_idx}:\")\n",
    "    print(f\"  Shape: {frame_attn.shape}\")\n",
    "    print(f\"  Min: {frame_attn.min():.6f}\")\n",
    "    print(f\"  Max: {frame_attn.max():.6f}\")\n",
    "    print(f\"  Mean: {frame_attn.mean():.6f}\")\n",
    "    print(f\"  Std: {frame_attn.std():.6f}\")\n",
    "    print(f\"  Sum: {frame_attn.sum():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 儲存 Attention Map 數值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存為 .npy 檔案供後續使用\n",
    "output_data = {\n",
    "    'global_attention_maps': global_values['attention_maps'],  # [3, grid_h, grid_w]\n",
    "    'global_attention_maps_resized': global_values['attention_maps_resized'],  # [3, H, W]\n",
    "    'frame_attention_map': frame_values['attention_maps'],  # [grid_h, grid_w]\n",
    "    'frame_attention_map_resized': frame_values['attention_maps_resized'],  # [H, W]\n",
    "    'metadata': {\n",
    "        'block_idx': block_idx,\n",
    "        'token_idx': token_idx,\n",
    "        'head_idx': head_idx,\n",
    "        **global_values['metadata']\n",
    "    }\n",
    "}\n",
    "\n",
    "# 儲存\n",
    "np.save('block9_token500_attention.npy', output_data)\n",
    "print(\"已儲存 attention maps 到 'block9_token500_attention.npy'\")\n",
    "\n",
    "# 顯示儲存的資料結構\n",
    "print(\"\\n儲存的資料結構：\")\n",
    "print(f\"  global_attention_maps: {output_data['global_attention_maps'].shape}\")\n",
    "print(f\"  global_attention_maps_resized: {output_data['global_attention_maps_resized'].shape}\")\n",
    "print(f\"  frame_attention_map: {output_data['frame_attention_map'].shape}\")\n",
    "print(f\"  frame_attention_map_resized: {output_data['frame_attention_map_resized'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. （可選）查看原始 Attention Weights\n",
    "\n",
    "如果你需要完整的 attention weight 矩陣（所有 token 之間的關係）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global attention: token 500 對所有其他 token 的 attention weights\n",
    "global_attn_weights = result['global_attention']['attn_weights']\n",
    "token_500_global_attn = global_attn_weights[0, head_idx, token_idx, :]  # [num_tokens]\n",
    "\n",
    "print(f\"Token 500 的 Global Attention Weights:\")\n",
    "print(f\"  Shape: {token_500_global_attn.shape}\")\n",
    "print(f\"  總 token 數: {token_500_global_attn.shape[0]}\")\n",
    "print(f\"  Sum (應該 ≈ 1.0): {token_500_global_attn.sum():.6f}\")\n",
    "\n",
    "# 找出 attention 最高的前 10 個 token\n",
    "top_k = 10\n",
    "top_indices = torch.topk(token_500_global_attn, k=top_k).indices\n",
    "top_values = torch.topk(token_500_global_attn, k=top_k).values\n",
    "\n",
    "print(f\"\\nAttention 最高的前 {top_k} 個 token:\")\n",
    "for i, (idx, val) in enumerate(zip(top_indices, top_values)):\n",
    "    print(f\"  #{i+1}: Token {idx.item()}, Attention = {val.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 總結\n",
    "\n",
    "本 notebook 提取了：\n",
    "\n",
    "1. **Global Attention Maps**: Token 500 對 3 個 frame 的注意力分佈\n",
    "   - `global_values['attention_maps']`: shape [3, grid_h, grid_w]\n",
    "   - `global_values['attention_maps_resized']`: shape [3, H, W]\n",
    "\n",
    "2. **Frame Attention Map**: Token 500 在單個 frame 內的注意力分佈\n",
    "   - `frame_values['attention_maps']`: shape [grid_h, grid_w]\n",
    "   - `frame_values['attention_maps_resized']`: shape [H, W]\n",
    "\n",
    "3. **原始 Attention Weights**: Token 500 對所有 token 的 attention weights\n",
    "   - `token_500_global_attn`: shape [num_tokens]\n",
    "\n",
    "所有數據已儲存到 `block9_token500_attention.npy`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
