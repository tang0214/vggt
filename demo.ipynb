{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e63e0",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nfrom vggt.models.vggt import VGGT\nfrom vggt.utils.load_fn import load_and_preprocess_images\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# bfloat16 is supported on Ampere GPUs (Compute Capability 8.0+) \ndtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16\n\n# Initialize the model and load the pretrained weights.\n# This will automatically download the model weights the first time it's run, which may take a while.\nmodel = VGGT.from_pretrained(\"facebook/VGGT-1B\").to(device)\n\n# Load and preprocess example images (flower scene from LLFF dataset)\nimage_names = [\n    \"examples/llff_flower/images/000.png\",\n    \"examples/llff_flower/images/005.png\",\n    \"examples/llff_flower/images/010.png\"\n]  \nimages = load_and_preprocess_images(image_names).to(device)\n\nwith torch.no_grad():\n    with torch.cuda.amp.autocast(dtype=dtype):\n        # Predict attributes including cameras, depth maps, and point maps.\n        predictions = model(images)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c72e7",
   "metadata": {},
   "outputs": [],
   "source": "# 查看 predictions 字典的所有 keys\nprint(\"=\" * 60)\nprint(\"Predictions 包含的所有 keys:\")\nprint(\"=\" * 60)\nfor key in predictions.keys():\n    print(f\"  • {key}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"各個預測結果的形狀 (shape):\")\nprint(\"=\" * 60)\nfor key, value in predictions.items():\n    if isinstance(value, torch.Tensor):\n        print(f\"{key:20s}: {list(value.shape)}\")\n    elif isinstance(value, list):\n        print(f\"{key:20s}: list with {len(value)} items\")\n        \nprint(\"\\n\" + \"=\" * 60)\nprint(\"說明:\")\nprint(\"=\" * 60)\nprint(\"  B = Batch size (批次大小)\")\nprint(\"  S = Sequence length (圖片數量)\")\nprint(\"  H = Height (圖片高度)\")\nprint(\"  W = Width (圖片寬度)\")"
  },
  {
   "cell_type": "markdown",
   "id": "wnr90d3tr6",
   "source": "# VGGT Demo - 花卉場景 3D 重建\n\n這個 notebook 展示如何使用 VGGT 模型進行 3D 場景重建。\n\n## Predictions 字典內容說明：\n\n- **`pose_enc`**: 相機姿態編碼 [B, S, 9]\n- **`depth`**: 深度圖 [B, S, H, W, 1] - 預測每個像素的深度\n- **`depth_conf`**: 深度置信度 [B, S, H, W] - 深度預測的可信度\n- **`world_points`**: 3D 世界座標 [B, S, H, W, 3] - 每個像素的 3D 位置 (x, y, z)\n- **`world_points_conf`**: 點雲置信度 [B, S, H, W] - 3D 點的可信度\n- **`images`**: 原始輸入圖片\n\n其中:\n- B = Batch size (批次大小，通常為 1)\n- S = Sequence length (圖片數量)\n- H, W = 圖片的高度和寬度",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "h12i2sbyyr5",
   "source": "# 顯示原始輸入圖片\noriginal_images = predictions['images'].cpu().numpy()  # [B, S, 3, H, W]\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nfig.suptitle('原始輸入圖片 (Original Input Images)', fontsize=16, fontweight='bold')\n\nfor i in range(3):\n    # 轉換從 [3, H, W] 到 [H, W, 3] 並調整到 [0, 1] 範圍\n    img = original_images[0, i].transpose(1, 2, 0)\n    img = np.clip(img, 0, 1)\n    \n    axes[i].imshow(img)\n    axes[i].set_title(f'Image {i}: {image_names[i].split(\"/\")[-1]}')\n    axes[i].axis('off')\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a96vkolux3",
   "source": "# 可視化 3D 世界點雲 (World Points)\nworld_points = predictions['world_points'].cpu().numpy()  # [B, S, H, W, 3]\nworld_points_conf = predictions['world_points_conf'].cpu().numpy()  # [B, S, H, W]\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\nfig.suptitle('3D World Points - XYZ 分量', fontsize=16, fontweight='bold')\n\nfor i in range(3):\n    wp = world_points[0, i]  # [H, W, 3]\n    \n    # 顯示 X, Y, Z 各個分量\n    for j, axis_name in enumerate(['X', 'Y', 'Z']):\n        if j < 3:\n            row = j // 3\n            col = i\n            if j == 0:\n                im = axes[0, col].imshow(wp[:, :, j], cmap='RdBu')\n                axes[0, col].set_title(f'Image {i}: {axis_name} coordinate')\n                axes[0, col].axis('off')\n                plt.colorbar(im, ax=axes[0, col], fraction=0.046)\n    \n    # 顯示 3D 點的置信度\n    conf = world_points_conf[0, i]\n    im = axes[1, i].imshow(conf, cmap='hot')\n    axes[1, i].set_title(f'Image {i}: World Points Confidence')\n    axes[1, i].axis('off')\n    plt.colorbar(im, ax=axes[1, i], fraction=0.046)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7rf2ij1su8w",
   "source": "# 可視化深度圖\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndepth_maps = predictions['depth'].cpu().numpy()  # [B, S, H, W, 1]\ndepth_conf = predictions['depth_conf'].cpu().numpy()  # [B, S, H, W]\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\nfig.suptitle('Depth Maps (深度圖) - 花卉場景', fontsize=16, fontweight='bold')\n\nfor i in range(3):\n    # 顯示深度圖\n    depth = depth_maps[0, i, :, :, 0]\n    im1 = axes[0, i].imshow(depth, cmap='turbo')\n    axes[0, i].set_title(f'Image {i}: Depth Map')\n    axes[0, i].axis('off')\n    plt.colorbar(im1, ax=axes[0, i], fraction=0.046)\n    \n    # 顯示深度置信度\n    conf = depth_conf[0, i]\n    im2 = axes[1, i].imshow(conf, cmap='hot')\n    axes[1, i].set_title(f'Image {i}: Depth Confidence')\n    axes[1, i].axis('off')\n    plt.colorbar(im2, ax=axes[1, i], fraction=0.046)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "lla4eigups",
   "source": "# 解碼相機參數 (Camera Parameters)\nfrom vggt.utils.pose_enc import pose_encoding_to_extri_intri\n\npose_enc = predictions['pose_enc']  # [B, S, 9]\nextrinsic, intrinsic = pose_encoding_to_extri_intri(\n    pose_enc, \n    predictions['images'].shape[-2:]  # (H, W)\n)\n\nprint(\"=\" * 60)\nprint(\"相機參數:\")\nprint(\"=\" * 60)\nprint(f\"Extrinsic (外參矩陣) shape: {extrinsic.shape}\")  # [B, S, 4, 4]\nprint(f\"Intrinsic (內參矩陣) shape: {intrinsic.shape}\")  # [B, S, 3, 3]\n\nprint(\"\\n第一張圖片的內參矩陣 (K matrix):\")\nprint(intrinsic[0, 0].cpu().numpy())\n\nprint(\"\\n第一張圖片的外參矩陣 (相機到世界坐標轉換):\")\nprint(extrinsic[0, 0].cpu().numpy())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vggt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}